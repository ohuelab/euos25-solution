seed: 42
folds: 5
scaffold_min_size: 10

featurizers:
  - name: ecfp
    params:
      radius: 3
      n_bits: 2048
      use_counts: true
  - name: rdkit2d
    params: {}
  - name: conj_proxy
    params:
      L_cut: 4

model:
  name: lgbm
  params:
    n_jobs: -1
    n_estimators: 1000
    learning_rate: 0.02
    max_depth: -1
    num_leaves: 255
    subsample: 0.8
    colsample_bytree: 0.8
    min_child_samples: 10
    reg_alpha: 0.1
    reg_lambda: 0.1

imbalance:
  # This will be overridden by Optuna's use_pos_weight parameter
  use_pos_weight: true
  pos_weight_from_data: true
  # Focal loss parameters (used when use_pos_weight=False)
  focal_alpha: 0.25
  focal_gamma: 2.0

plates:
  normalize: false

task: y_fluo_any
metrics:
  - roc_auc
  - pr_auc

early_stopping_rounds: 30
early_stopping_metric: roc_auc

log_level: INFO

# Optuna hyperparameter tuning configuration
optuna:
  enable: true
  n_trials: 100
  timeout: null
  study_name: full_imbalance_tuning

  # LGBM parameters to tune
  lgbm_params:
    learning_rate:
      type: float
      min: 0.01
      max: 0.08
    num_leaves:
      type: int
      min: 63
      max: 511
    min_child_samples:
      type: int
      min: 5
      max: 50
    reg_alpha:
      type: float
      min: 0.001
      max: 1.0
      log: true

  # Imbalance strategy to tune: pos_weight vs focal loss
  imbalance_params:
    use_pos_weight:
      type: categorical
      choices: [true, false]  # true=pos_weight, false=focal_loss

  # pos_weight parameters (used when use_pos_weight=True)
  pos_weight_params:
    pos_weight_multiplier:
      type: float
      min: 0.5
      max: 2.0

  # Focal loss parameters (used when use_pos_weight=False)
  focal_params:
    focal_alpha:
      type: float
      min: 0.1
      max: 0.5
    focal_gamma:
      type: float
      min: 1.0
      max: 3.0
    focal_scale:
      type: float
      min: 10.0
      max: 200.0
